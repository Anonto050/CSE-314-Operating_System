diff --git a/.vscode/settings.json b/.vscode/settings.json
new file mode 100644
index 0000000..e62a388
--- /dev/null
+++ b/.vscode/settings.json
@@ -0,0 +1,5 @@
+{
+    "files.associations": {
+        "memlayout.h": "c"
+    }
+}
\ No newline at end of file
diff --git a/Makefile b/Makefile
index 39a99d7..75d686d 100644
--- a/Makefile
+++ b/Makefile
@@ -132,7 +132,9 @@ UPROGS=\
 	$U/_grind\
 	$U/_wc\
 	$U/_zombie\
-
+	$U/_threads\
+	$U/_producer_consumer\
+	
 fs.img: mkfs/mkfs README $(UPROGS)
 	mkfs/mkfs fs.img README $(UPROGS)
 
diff --git a/kernel/defs.h b/kernel/defs.h
index a3c962b..abdb690 100644
--- a/kernel/defs.h
+++ b/kernel/defs.h
@@ -89,6 +89,7 @@ int             growproc(int);
 void            proc_mapstacks(pagetable_t);
 pagetable_t     proc_pagetable(struct proc *);
 void            proc_freepagetable(pagetable_t, uint64);
+void            proc_free_thread_pagetable(pagetable_t, uint64);
 int             kill(int);
 int             killed(struct proc*);
 void            setkilled(struct proc*);
@@ -106,6 +107,10 @@ void            yield(void);
 int             either_copyout(int user_dst, uint64 dst, void *src, uint64 len);
 int             either_copyin(void *dst, int user_src, uint64 src, uint64 len);
 void            procdump(void);
+int             thread_create(void (*)(void *), void*, void*);
+int             thread_join(int);
+void            thread_exit(void);
+void            thread_wakeup(int);
 
 // swtch.S
 void            swtch(struct context*, struct context*);
@@ -165,7 +170,10 @@ void            uvmfirst(pagetable_t, uchar *, uint);
 uint64          uvmalloc(pagetable_t, uint64, uint64, int);
 uint64          uvmdealloc(pagetable_t, uint64, uint64);
 int             uvmcopy(pagetable_t, pagetable_t, uint64);
+int             uvmmirror(pagetable_t, pagetable_t, uint64);
+int             uvmmirrorgrow(pagetable_t, pagetable_t, uint64, uint64);
 void            uvmfree(pagetable_t, uint64);
+void            uvmfreethread(pagetable_t, uint64);
 void            uvmunmap(pagetable_t, uint64, uint64, int);
 void            uvmclear(pagetable_t, uint64);
 pte_t *         walk(pagetable_t, uint64, int);
@@ -173,6 +181,7 @@ uint64          walkaddr(pagetable_t, uint64);
 int             copyout(pagetable_t, uint64, char *, uint64);
 int             copyin(pagetable_t, char *, uint64, uint64);
 int             copyinstr(pagetable_t, char *, uint64, uint64);
+int             copyoutlock(pagetable_t, uint64);
 
 // plic.c
 void            plicinit(void);
diff --git a/kernel/proc.c b/kernel/proc.c
index 959b778..4798e48 100644
--- a/kernel/proc.c
+++ b/kernel/proc.c
@@ -13,7 +13,9 @@ struct proc proc[NPROC];
 struct proc *initproc;
 
 int nextpid = 1;
+int nextmem_id = 1;
 struct spinlock pid_lock;
+struct spinlock mem_id_lock;
 
 extern void forkret(void);
 static void freeproc(struct proc *p);
@@ -29,40 +31,45 @@ struct spinlock wait_lock;
 // Allocate a page for each process's kernel stack.
 // Map it high in memory, followed by an invalid
 // guard page.
-void
-proc_mapstacks(pagetable_t kpgtbl)
+void proc_mapstacks(pagetable_t kpgtbl)
 {
   struct proc *p;
-  
-  for(p = proc; p < &proc[NPROC]; p++) {
+
+  for (p = proc; p < &proc[NPROC]; p++)
+  {
     char *pa = kalloc();
-    if(pa == 0)
+    if (pa == 0)
       panic("kalloc");
-    uint64 va = KSTACK((int) (p - proc));
+    uint64 va = KSTACK((int)(p - proc));
     kvmmap(kpgtbl, va, (uint64)pa, PGSIZE, PTE_R | PTE_W);
   }
 }
 
 // initialize the proc table.
-void
-procinit(void)
+void procinit(void)
 {
   struct proc *p;
-  
+
   initlock(&pid_lock, "nextpid");
+  initlock(&mem_id_lock, "nextmem_id");
   initlock(&wait_lock, "wait_lock");
-  for(p = proc; p < &proc[NPROC]; p++) {
-      initlock(&p->lock, "proc");
-      p->state = UNUSED;
-      p->kstack = KSTACK((int) (p - proc));
+  for (p = proc; p < &proc[NPROC]; p++)
+  {
+    initlock(&p->lock, "proc");
+
+    // Initialize memory lock for each process
+    p->mem_lock = (struct spinlock *)kalloc();
+    initlock(p->mem_lock, "mem_lock");
+
+    p->state = UNUSED;
+    p->kstack = KSTACK((int)(p - proc));
   }
 }
 
 // Must be called with interrupts disabled,
 // to prevent race with process being moved
 // to a different CPU.
-int
-cpuid()
+int cpuid()
 {
   int id = r_tp();
   return id;
@@ -70,7 +77,7 @@ cpuid()
 
 // Return this CPU's cpu struct.
 // Interrupts must be disabled.
-struct cpu*
+struct cpu *
 mycpu(void)
 {
   int id = cpuid();
@@ -79,7 +86,7 @@ mycpu(void)
 }
 
 // Return the current struct proc *, or zero if none.
-struct proc*
+struct proc *
 myproc(void)
 {
   push_off();
@@ -89,11 +96,10 @@ myproc(void)
   return p;
 }
 
-int
-allocpid()
+int allocpid()
 {
   int pid;
-  
+
   acquire(&pid_lock);
   pid = nextpid;
   nextpid = nextpid + 1;
@@ -102,20 +108,36 @@ allocpid()
   return pid;
 }
 
+int allocmem_id()
+{
+  int mem_id;
+
+  acquire(&mem_id_lock);
+  mem_id = nextmem_id;
+  nextmem_id = nextmem_id + 1;
+  release(&mem_id_lock);
+
+  return mem_id;
+}
+
 // Look in the process table for an UNUSED proc.
 // If found, initialize state required to run in the kernel,
 // and return with p->lock held.
 // If there are no free procs, or a memory allocation fails, return 0.
-static struct proc*
+static struct proc *
 allocproc(void)
 {
   struct proc *p;
 
-  for(p = proc; p < &proc[NPROC]; p++) {
+  for (p = proc; p < &proc[NPROC]; p++)
+  {
     acquire(&p->lock);
-    if(p->state == UNUSED) {
+    if (p->state == UNUSED)
+    {
       goto found;
-    } else {
+    }
+    else
+    {
       release(&p->lock);
     }
   }
@@ -123,10 +145,13 @@ allocproc(void)
 
 found:
   p->pid = allocpid();
+  p->mem_id = allocmem_id();
   p->state = USED;
+  p->is_thread = 0;
 
   // Allocate a trapframe page.
-  if((p->trapframe = (struct trapframe *)kalloc()) == 0){
+  if ((p->trapframe = (struct trapframe *)kalloc()) == 0)
+  {
     freeproc(p);
     release(&p->lock);
     return 0;
@@ -134,7 +159,8 @@ found:
 
   // An empty user page table.
   p->pagetable = proc_pagetable(p);
-  if(p->pagetable == 0){
+  if (p->pagetable == 0)
+  {
     freeproc(p);
     release(&p->lock);
     return 0;
@@ -155,14 +181,19 @@ found:
 static void
 freeproc(struct proc *p)
 {
-  if(p->trapframe)
-    kfree((void*)p->trapframe);
+  if (p->trapframe)
+    kfree((void *)p->trapframe);
   p->trapframe = 0;
-  if(p->pagetable)
+
+  if (p->is_thread == 0 && p->pagetable)
     proc_freepagetable(p->pagetable, p->sz);
+  else if (p->is_thread == 1 && p->pagetable)
+    proc_free_thread_pagetable(p->pagetable, p->sz);
+
   p->pagetable = 0;
   p->sz = 0;
   p->pid = 0;
+  p->mem_id = 0;
   p->parent = 0;
   p->name[0] = 0;
   p->chan = 0;
@@ -180,23 +211,25 @@ proc_pagetable(struct proc *p)
 
   // An empty page table.
   pagetable = uvmcreate();
-  if(pagetable == 0)
+  if (pagetable == 0)
     return 0;
 
   // map the trampoline code (for system call return)
   // at the highest user virtual address.
   // only the supervisor uses it, on the way
   // to/from user space, so not PTE_U.
-  if(mappages(pagetable, TRAMPOLINE, PGSIZE,
-              (uint64)trampoline, PTE_R | PTE_X) < 0){
+  if (mappages(pagetable, TRAMPOLINE, PGSIZE,
+               (uint64)trampoline, PTE_R | PTE_X) < 0)
+  {
     uvmfree(pagetable, 0);
     return 0;
   }
 
   // map the trapframe page just below the trampoline page, for
   // trampoline.S.
-  if(mappages(pagetable, TRAPFRAME, PGSIZE,
-              (uint64)(p->trapframe), PTE_R | PTE_W) < 0){
+  if (mappages(pagetable, TRAPFRAME, PGSIZE,
+               (uint64)(p->trapframe), PTE_R | PTE_W) < 0)
+  {
     uvmunmap(pagetable, TRAMPOLINE, 1, 0);
     uvmfree(pagetable, 0);
     return 0;
@@ -207,44 +240,48 @@ proc_pagetable(struct proc *p)
 
 // Free a process's page table, and free the
 // physical memory it refers to.
-void
-proc_freepagetable(pagetable_t pagetable, uint64 sz)
+void proc_freepagetable(pagetable_t pagetable, uint64 sz)
 {
   uvmunmap(pagetable, TRAMPOLINE, 1, 0);
   uvmunmap(pagetable, TRAPFRAME, 1, 0);
   uvmfree(pagetable, sz);
 }
 
+void proc_free_thread_pagetable(pagetable_t pagetable, uint64 sz)
+{
+  uvmunmap(pagetable, TRAMPOLINE, 1, 0);
+  uvmunmap(pagetable, TRAPFRAME, 1, 0);
+  uvmfreethread(pagetable, sz);
+}
+
 // a user program that calls exec("/init")
 // assembled from ../user/initcode.S
 // od -t xC ../user/initcode
 uchar initcode[] = {
-  0x17, 0x05, 0x00, 0x00, 0x13, 0x05, 0x45, 0x02,
-  0x97, 0x05, 0x00, 0x00, 0x93, 0x85, 0x35, 0x02,
-  0x93, 0x08, 0x70, 0x00, 0x73, 0x00, 0x00, 0x00,
-  0x93, 0x08, 0x20, 0x00, 0x73, 0x00, 0x00, 0x00,
-  0xef, 0xf0, 0x9f, 0xff, 0x2f, 0x69, 0x6e, 0x69,
-  0x74, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x00,
-  0x00, 0x00, 0x00, 0x00
-};
+    0x17, 0x05, 0x00, 0x00, 0x13, 0x05, 0x45, 0x02,
+    0x97, 0x05, 0x00, 0x00, 0x93, 0x85, 0x35, 0x02,
+    0x93, 0x08, 0x70, 0x00, 0x73, 0x00, 0x00, 0x00,
+    0x93, 0x08, 0x20, 0x00, 0x73, 0x00, 0x00, 0x00,
+    0xef, 0xf0, 0x9f, 0xff, 0x2f, 0x69, 0x6e, 0x69,
+    0x74, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x00,
+    0x00, 0x00, 0x00, 0x00};
 
 // Set up first user process.
-void
-userinit(void)
+void userinit(void)
 {
   struct proc *p;
 
   p = allocproc();
   initproc = p;
-  
+
   // allocate one user page and copy initcode's instructions
   // and data into it.
   uvmfirst(p->pagetable, initcode, sizeof(initcode));
   p->sz = PGSIZE;
 
   // prepare for the very first "return" from kernel to user.
-  p->trapframe->epc = 0;      // user program counter
-  p->trapframe->sp = PGSIZE;  // user stack pointer
+  p->trapframe->epc = 0;     // user program counter
+  p->trapframe->sp = PGSIZE; // user stack pointer
 
   safestrcpy(p->name, "initcode", sizeof(p->name));
   p->cwd = namei("/");
@@ -256,40 +293,73 @@ userinit(void)
 
 // Grow or shrink user memory by n bytes.
 // Return 0 on success, -1 on failure.
-int
-growproc(int n)
+int growproc(int n)
 {
+
   uint64 sz;
+  uint64 oldsz;
   struct proc *p = myproc();
 
+  acquire(p->mem_lock); // acquire lock for memory
   sz = p->sz;
-  if(n > 0){
-    if((sz = uvmalloc(p->pagetable, sz, sz + n, PTE_W)) == 0) {
+  oldsz = sz;
+
+  if (n > 0)
+  {
+    if ((sz = uvmalloc(p->pagetable, sz, sz + n, PTE_W)) == 0)
+    {
       return -1;
     }
-  } else if(n < 0){
+  }
+  else if (n < 0)
+  {
     sz = uvmdealloc(p->pagetable, sz, sz + n);
   }
   p->sz = sz;
+
+  // Loop over all processes with the same mem_id (excluding self), since the change in size should be available to all threads
+  for (struct proc *p2 = proc; p2 < &proc[NPROC]; p2++)
+  {
+    if (p2->mem_id == p->mem_id && p2 != p)
+    {
+      if (n >= 0)
+      {
+        if (uvmmirrorgrow(p->pagetable, p2->pagetable, oldsz, sz) < 0)
+        {
+          return -1;
+        }
+      }
+      else
+      {
+        // We'll use uvmunmap() to unmap the pages from processes with the same mem_id
+        // Here, we will start from PGROUNDUP(new size). Here, new size < old size.
+        // The third parameter will be (PGROUNDUP(old size) - PGROUNDUP(new size)) / PGSIZE;
+        uvmunmap(p2->pagetable, PGROUNDUP(sz), (PGROUNDUP(oldsz) - PGROUNDUP(sz)) / PGSIZE, 0);
+      }
+    }
+  }
+
+  release(p->mem_lock); // release lock for memory
   return 0;
 }
 
 // Create a new process, copying the parent.
 // Sets up child kernel stack to return as if from fork() system call.
-int
-fork(void)
+int fork(void)
 {
   int i, pid;
   struct proc *np;
   struct proc *p = myproc();
 
   // Allocate process.
-  if((np = allocproc()) == 0){
+  if ((np = allocproc()) == 0)
+  {
     return -1;
   }
 
   // Copy user memory from parent to child.
-  if(uvmcopy(p->pagetable, np->pagetable, p->sz) < 0){
+  if (uvmcopy(p->pagetable, np->pagetable, p->sz) < 0)
+  {
     freeproc(np);
     release(&np->lock);
     return -1;
@@ -302,9 +372,11 @@ fork(void)
   // Cause fork to return 0 in the child.
   np->trapframe->a0 = 0;
 
+  np->is_thread = p->is_thread;
+
   // increment reference counts on open file descriptors.
-  for(i = 0; i < NOFILE; i++)
-    if(p->ofile[i])
+  for (i = 0; i < NOFILE; i++)
+    if (p->ofile[i])
       np->ofile[i] = filedup(p->ofile[i]);
   np->cwd = idup(p->cwd);
 
@@ -327,13 +399,14 @@ fork(void)
 
 // Pass p's abandoned children to init.
 // Caller must hold wait_lock.
-void
-reparent(struct proc *p)
+void reparent(struct proc *p)
 {
   struct proc *pp;
 
-  for(pp = proc; pp < &proc[NPROC]; pp++){
-    if(pp->parent == p){
+  for (pp = proc; pp < &proc[NPROC]; pp++)
+  {
+    if (pp->parent == p)
+    {
       pp->parent = initproc;
       wakeup(initproc);
     }
@@ -343,17 +416,18 @@ reparent(struct proc *p)
 // Exit the current process.  Does not return.
 // An exited process remains in the zombie state
 // until its parent calls wait().
-void
-exit(int status)
+void exit(int status)
 {
   struct proc *p = myproc();
 
-  if(p == initproc)
+  if (p == initproc)
     panic("init exiting");
 
   // Close all open files.
-  for(int fd = 0; fd < NOFILE; fd++){
-    if(p->ofile[fd]){
+  for (int fd = 0; fd < NOFILE; fd++)
+  {
+    if (p->ofile[fd])
+    {
       struct file *f = p->ofile[fd];
       fileclose(f);
       p->ofile[fd] = 0;
@@ -372,7 +446,7 @@ exit(int status)
 
   // Parent might be sleeping in wait().
   wakeup(p->parent);
-  
+
   acquire(&p->lock);
 
   p->xstate = status;
@@ -387,8 +461,7 @@ exit(int status)
 
 // Wait for a child process to exit and return its pid.
 // Return -1 if this process has no children.
-int
-wait(uint64 addr)
+int wait(uint64 addr)
 {
   struct proc *pp;
   int havekids, pid;
@@ -396,20 +469,25 @@ wait(uint64 addr)
 
   acquire(&wait_lock);
 
-  for(;;){
+  for (;;)
+  {
     // Scan through table looking for exited children.
     havekids = 0;
-    for(pp = proc; pp < &proc[NPROC]; pp++){
-      if(pp->parent == p){
+    for (pp = proc; pp < &proc[NPROC]; pp++)
+    {
+      if (pp->parent == p)
+      {
         // make sure the child isn't still in exit() or swtch().
         acquire(&pp->lock);
 
         havekids = 1;
-        if(pp->state == ZOMBIE){
+        if (pp->state == ZOMBIE)
+        {
           // Found one.
           pid = pp->pid;
-          if(addr != 0 && copyout(p->pagetable, addr, (char *)&pp->xstate,
-                                  sizeof(pp->xstate)) < 0) {
+          if (addr != 0 && copyout(p->pagetable, addr, (char *)&pp->xstate,
+                                   sizeof(pp->xstate)) < 0)
+          {
             release(&pp->lock);
             release(&wait_lock);
             return -1;
@@ -424,13 +502,14 @@ wait(uint64 addr)
     }
 
     // No point waiting if we don't have any children.
-    if(!havekids || killed(p)){
+    if (!havekids || killed(p))
+    {
       release(&wait_lock);
       return -1;
     }
-    
+
     // Wait for a child to exit.
-    sleep(p, &wait_lock);  //DOC: wait-sleep
+    sleep(p, &wait_lock); // DOC: wait-sleep
   }
 }
 
@@ -441,20 +520,22 @@ wait(uint64 addr)
 //  - swtch to start running that process.
 //  - eventually that process transfers control
 //    via swtch back to the scheduler.
-void
-scheduler(void)
+void scheduler(void)
 {
   struct proc *p;
   struct cpu *c = mycpu();
-  
+
   c->proc = 0;
-  for(;;){
+  for (;;)
+  {
     // Avoid deadlock by ensuring that devices can interrupt.
     intr_on();
 
-    for(p = proc; p < &proc[NPROC]; p++) {
+    for (p = proc; p < &proc[NPROC]; p++)
+    {
       acquire(&p->lock);
-      if(p->state == RUNNABLE) {
+      if (p->state == RUNNABLE)
+      {
         // Switch to chosen process.  It is the process's job
         // to release its lock and then reacquire it
         // before jumping back to us.
@@ -478,19 +559,18 @@ scheduler(void)
 // be proc->intena and proc->noff, but that would
 // break in the few places where a lock is held but
 // there's no process.
-void
-sched(void)
+void sched(void)
 {
   int intena;
   struct proc *p = myproc();
 
-  if(!holding(&p->lock))
+  if (!holding(&p->lock))
     panic("sched p->lock");
-  if(mycpu()->noff != 1)
+  if (mycpu()->noff != 1)
     panic("sched locks");
-  if(p->state == RUNNING)
+  if (p->state == RUNNING)
     panic("sched running");
-  if(intr_get())
+  if (intr_get())
     panic("sched interruptible");
 
   intena = mycpu()->intena;
@@ -499,8 +579,7 @@ sched(void)
 }
 
 // Give up the CPU for one scheduling round.
-void
-yield(void)
+void yield(void)
 {
   struct proc *p = myproc();
   acquire(&p->lock);
@@ -511,15 +590,15 @@ yield(void)
 
 // A fork child's very first scheduling by scheduler()
 // will swtch to forkret.
-void
-forkret(void)
+void forkret(void)
 {
   static int first = 1;
 
   // Still holding p->lock from scheduler.
   release(&myproc()->lock);
 
-  if (first) {
+  if (first)
+  {
     // File system initialization must be run in the context of a
     // regular process (e.g., because it calls sleep), and thus cannot
     // be run from main().
@@ -532,11 +611,10 @@ forkret(void)
 
 // Atomically release lock and sleep on chan.
 // Reacquires lock when awakened.
-void
-sleep(void *chan, struct spinlock *lk)
+void sleep(void *chan, struct spinlock *lk)
 {
   struct proc *p = myproc();
-  
+
   // Must acquire p->lock in order to
   // change p->state and then call sched.
   // Once we hold p->lock, we can be
@@ -544,7 +622,7 @@ sleep(void *chan, struct spinlock *lk)
   // (wakeup locks p->lock),
   // so it's okay to release lk.
 
-  acquire(&p->lock);  //DOC: sleeplock1
+  acquire(&p->lock); // DOC: sleeplock1
   release(lk);
 
   // Go to sleep.
@@ -563,15 +641,36 @@ sleep(void *chan, struct spinlock *lk)
 
 // Wake up all processes sleeping on chan.
 // Must be called without any p->lock.
-void
-wakeup(void *chan)
+void wakeup(void *chan)
+{
+  struct proc *p;
+
+  for (p = proc; p < &proc[NPROC]; p++)
+  {
+    if (p != myproc())
+    {
+      acquire(&p->lock);
+      if (p->state == SLEEPING && p->chan == chan)
+      {
+        p->state = RUNNABLE;
+      }
+      release(&p->lock);
+    }
+  }
+}
+
+// thread wakeup
+void thread_wakeup(int thread_id)
 {
   struct proc *p;
 
-  for(p = proc; p < &proc[NPROC]; p++) {
-    if(p != myproc()){
+  for (p = proc; p < &proc[NPROC]; p++)
+  {
+    if (p->pid == thread_id)
+    {
       acquire(&p->lock);
-      if(p->state == SLEEPING && p->chan == chan) {
+      if (p->state == SLEEPING)
+      {
         p->state = RUNNABLE;
       }
       release(&p->lock);
@@ -582,16 +681,18 @@ wakeup(void *chan)
 // Kill the process with the given pid.
 // The victim won't exit until it tries to return
 // to user space (see usertrap() in trap.c).
-int
-kill(int pid)
+int kill(int pid)
 {
   struct proc *p;
 
-  for(p = proc; p < &proc[NPROC]; p++){
+  for (p = proc; p < &proc[NPROC]; p++)
+  {
     acquire(&p->lock);
-    if(p->pid == pid){
+    if (p->pid == pid)
+    {
       p->killed = 1;
-      if(p->state == SLEEPING){
+      if (p->state == SLEEPING)
+      {
         // Wake process from sleep().
         p->state = RUNNABLE;
       }
@@ -603,19 +704,17 @@ kill(int pid)
   return -1;
 }
 
-void
-setkilled(struct proc *p)
+void setkilled(struct proc *p)
 {
   acquire(&p->lock);
   p->killed = 1;
   release(&p->lock);
 }
 
-int
-killed(struct proc *p)
+int killed(struct proc *p)
 {
   int k;
-  
+
   acquire(&p->lock);
   k = p->killed;
   release(&p->lock);
@@ -625,13 +724,15 @@ killed(struct proc *p)
 // Copy to either a user address, or kernel address,
 // depending on usr_dst.
 // Returns 0 on success, -1 on error.
-int
-either_copyout(int user_dst, uint64 dst, void *src, uint64 len)
+int either_copyout(int user_dst, uint64 dst, void *src, uint64 len)
 {
   struct proc *p = myproc();
-  if(user_dst){
+  if (user_dst)
+  {
     return copyout(p->pagetable, dst, src, len);
-  } else {
+  }
+  else
+  {
     memmove((char *)dst, src, len);
     return 0;
   }
@@ -640,14 +741,16 @@ either_copyout(int user_dst, uint64 dst, void *src, uint64 len)
 // Copy from either a user address, or kernel address,
 // depending on usr_src.
 // Returns 0 on success, -1 on error.
-int
-either_copyin(void *dst, int user_src, uint64 src, uint64 len)
+int either_copyin(void *dst, int user_src, uint64 src, uint64 len)
 {
   struct proc *p = myproc();
-  if(user_src){
+  if (user_src)
+  {
     return copyin(p->pagetable, dst, src, len);
-  } else {
-    memmove(dst, (char*)src, len);
+  }
+  else
+  {
+    memmove(dst, (char *)src, len);
     return 0;
   }
 }
@@ -655,25 +758,24 @@ either_copyin(void *dst, int user_src, uint64 src, uint64 len)
 // Print a process listing to console.  For debugging.
 // Runs when user types ^P on console.
 // No lock to avoid wedging a stuck machine further.
-void
-procdump(void)
+void procdump(void)
 {
   static char *states[] = {
-  [UNUSED]    "unused",
-  [USED]      "used",
-  [SLEEPING]  "sleep ",
-  [RUNNABLE]  "runble",
-  [RUNNING]   "run   ",
-  [ZOMBIE]    "zombie"
-  };
+      [UNUSED] "unused",
+      [USED] "used",
+      [SLEEPING] "sleep ",
+      [RUNNABLE] "runble",
+      [RUNNING] "run   ",
+      [ZOMBIE] "zombie"};
   struct proc *p;
   char *state;
 
   printf("\n");
-  for(p = proc; p < &proc[NPROC]; p++){
-    if(p->state == UNUSED)
+  for (p = proc; p < &proc[NPROC]; p++)
+  {
+    if (p->state == UNUSED)
       continue;
-    if(p->state >= 0 && p->state < NELEM(states) && states[p->state])
+    if (p->state >= 0 && p->state < NELEM(states) && states[p->state])
       state = states[p->state];
     else
       state = "???";
@@ -681,3 +783,159 @@ procdump(void)
     printf("\n");
   }
 }
+
+// thread create
+int thread_create(void (*fcn)(void *), void *arg, void *stack)
+{
+  int i, mid;
+  struct proc *np;
+  struct proc *p = myproc();
+
+  // Allocate process.
+  if ((np = allocproc()) == 0)
+  {
+    return -1;
+  }
+
+  if (uvmmirror(p->pagetable, np->pagetable, p->sz) < 0)
+  {
+    freeproc(np);
+    release(&np->lock);
+    return -1;
+  }
+
+  np->sz = p->sz;
+
+  // copy saved user registers.
+  *(np->trapframe) = *(p->trapframe);
+
+  // set up new trapframe
+  np->trapframe->epc = (uint64)fcn;
+  np->trapframe->a0 = (uint64)arg;
+  np->trapframe->sp = (uint64)stack + PGSIZE - sizeof(void *);
+
+  np->is_thread = 1;
+
+  // Assign parent mem_id to child
+  np->mem_id = p->mem_id;
+  np->mem_lock = p->mem_lock;
+
+  // increment reference counts on open file descriptors.
+  for (i = 0; i < NOFILE; i++)
+    if (p->ofile[i])
+      np->ofile[i] = filedup(p->ofile[i]);
+  np->cwd = idup(p->cwd);
+
+  safestrcpy(np->name, p->name, sizeof(p->name));
+
+  mid = np->pid;
+
+  release(&np->lock);
+
+  acquire(&wait_lock);
+  np->parent = p;
+  release(&wait_lock);
+
+  acquire(&np->lock);
+  np->state = RUNNABLE;
+  release(&np->lock);
+
+  return mid;
+}
+
+// thread join
+int thread_join(int pid)
+{
+  struct proc *p;
+  int havekids;
+  struct proc *cp = myproc();
+
+  acquire(&wait_lock);
+
+  for (;;)
+  {
+    // Scan through table looking for exited children.
+    havekids = 0;
+    for (p = proc; p < &proc[NPROC]; p++)
+    {
+      if (p != cp && p->parent == cp && p->is_thread == 1)
+      {
+        // make sure the child isn't still in exit() or swtch().
+        acquire(p->mem_lock);
+        acquire(&p->lock);
+
+        havekids = 1;
+        if (p->pid == pid)
+        {
+          // Found one.
+          if (p->state == ZOMBIE)
+          {
+            // Found one.
+            freeproc(p);
+            release(&p->lock);
+            release(p->mem_lock);
+            release(&wait_lock);
+            return pid;
+          }
+        }
+
+        release(&p->lock);
+        release(p->mem_lock);
+      }
+    }
+
+    // No point waiting if we don't have any children.
+    if (!havekids)
+    {
+      release(&wait_lock);
+      return -1;
+    }
+
+    // Wait for a child to exit.
+    sleep(cp, &wait_lock); // DOC: wait-sleep
+  }
+}
+
+// thread exit
+void thread_exit()
+{
+  struct proc *p = myproc();
+
+  if (p == initproc)
+    panic("init exiting");
+
+  // Close all open files.
+  for (int fd = 0; fd < NOFILE; fd++)
+  {
+    if (p->ofile[fd])
+    {
+      struct file *f = p->ofile[fd];
+      fileclose(f);
+      p->ofile[fd] = 0;
+    }
+  }
+
+  begin_op();
+  iput(p->cwd);
+  end_op();
+  p->cwd = 0;
+
+  acquire(&wait_lock);
+
+  // Give any children to init.
+  reparent(p);
+
+  // Parent might be sleeping in wait().
+  wakeup(p->parent);
+
+  acquire(&p->lock);
+
+  // p->xstate = status;
+  p->state = ZOMBIE;
+
+  release(&wait_lock);
+
+  // Jump into the scheduler, never to return.
+  sched();
+  panic("zombie exit");
+}
\ No newline at end of file
diff --git a/kernel/proc.h b/kernel/proc.h
index d021857..60a6584 100644
--- a/kernel/proc.h
+++ b/kernel/proc.h
@@ -104,4 +104,9 @@ struct proc {
   struct file *ofile[NOFILE];  // Open files
   struct inode *cwd;           // Current directory
   char name[16];               // Process name (debugging)
+
+  // thread stuff
+  int is_thread;               // 1 if thread, 0 if process
+  int mem_id;                  // memory id
+  struct spinlock *mem_lock;    // lock for memory
 };
diff --git a/kernel/syscall.c b/kernel/syscall.c
index ed65409..a88312e 100644
--- a/kernel/syscall.c
+++ b/kernel/syscall.c
@@ -101,6 +101,11 @@ extern uint64 sys_unlink(void);
 extern uint64 sys_link(void);
 extern uint64 sys_mkdir(void);
 extern uint64 sys_close(void);
+extern uint64 sys_thread_create(void);
+extern uint64 sys_thread_join(void);
+extern uint64 sys_thread_exit(void);
+extern uint64 sys_thread_sleep(void);
+extern uint64 sys_thread_wakeup(void);
 
 // An array mapping syscall numbers from syscall.h
 // to the function that handles the system call.
@@ -126,6 +131,11 @@ static uint64 (*syscalls[])(void) = {
 [SYS_link]    sys_link,
 [SYS_mkdir]   sys_mkdir,
 [SYS_close]   sys_close,
+[SYS_thread_create] sys_thread_create,
+[SYS_thread_join] sys_thread_join,
+[SYS_thread_exit] sys_thread_exit,
+[SYS_thread_sleep] sys_thread_sleep,
+[SYS_thread_wakeup] sys_thread_wakeup,
 };
 
 void
diff --git a/kernel/syscall.h b/kernel/syscall.h
index bc5f356..a7ef698 100644
--- a/kernel/syscall.h
+++ b/kernel/syscall.h
@@ -20,3 +20,8 @@
 #define SYS_link   19
 #define SYS_mkdir  20
 #define SYS_close  21
+#define SYS_thread_create 22
+#define SYS_thread_join 23
+#define SYS_thread_exit 24
+#define SYS_thread_sleep 25
+#define SYS_thread_wakeup 26
\ No newline at end of file
diff --git a/kernel/sysproc.c b/kernel/sysproc.c
index 1de184e..739ee17 100644
--- a/kernel/sysproc.c
+++ b/kernel/sysproc.c
@@ -89,3 +89,61 @@ sys_uptime(void)
   release(&tickslock);
   return xticks;
 }
+
+// thread_create
+uint64
+sys_thread_create(void)
+{
+  uint64 func, arg, stack;
+  argaddr(0, &func);
+  argaddr(1, &arg);
+  argaddr(2, &stack);
+  return thread_create((void (*)(void*))func, (void*)arg, (void*)stack);
+}
+
+// thread_join
+uint64
+sys_thread_join(void)
+{
+  int thread_id;
+  argint(0, &thread_id);
+  return thread_join(thread_id);
+}
+
+// thread_exit
+uint64
+sys_thread_exit(void)
+{
+  thread_exit();
+  return 0;
+}
+
+// thread_sleep
+uint64
+sys_thread_sleep(void)
+{
+  uint64 mlocked;
+
+  argaddr(0, &mlocked);
+  //printf("mlocked: %d\n", mlocked);
+  
+  struct proc *p = myproc();
+  acquire(&p->lock);
+  copyoutlock(p->pagetable, mlocked);
+
+  p->state = SLEEPING;
+  sched();
+  release(&p->lock);
+
+  return 0;
+}
+
+// thread_wakeup
+uint64
+sys_thread_wakeup(void)
+{
+  int thread_id;
+  argint(0, &thread_id);
+  thread_wakeup(thread_id);
+  return 0;
+}
diff --git a/kernel/vm.c b/kernel/vm.c
index 9f69783..cbe800a 100644
--- a/kernel/vm.c
+++ b/kernel/vm.c
@@ -11,7 +11,7 @@
  */
 pagetable_t kernel_pagetable;
 
-extern char etext[];  // kernel.ld sets this to end of kernel code.
+extern char etext[]; // kernel.ld sets this to end of kernel code.
 
 extern char trampoline[]; // trampoline.S
 
@@ -21,7 +21,7 @@ kvmmake(void)
 {
   pagetable_t kpgtbl;
 
-  kpgtbl = (pagetable_t) kalloc();
+  kpgtbl = (pagetable_t)kalloc();
   memset(kpgtbl, 0, PGSIZE);
 
   // uart registers
@@ -34,10 +34,10 @@ kvmmake(void)
   kvmmap(kpgtbl, PLIC, PLIC, 0x400000, PTE_R | PTE_W);
 
   // map kernel text executable and read-only.
-  kvmmap(kpgtbl, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);
+  kvmmap(kpgtbl, KERNBASE, KERNBASE, (uint64)etext - KERNBASE, PTE_R | PTE_X);
 
   // map kernel data and the physical RAM we'll make use of.
-  kvmmap(kpgtbl, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);
+  kvmmap(kpgtbl, (uint64)etext, (uint64)etext, PHYSTOP - (uint64)etext, PTE_R | PTE_W);
 
   // map the trampoline for trap entry/exit to
   // the highest virtual address in the kernel.
@@ -45,21 +45,19 @@ kvmmake(void)
 
   // allocate and map a kernel stack for each process.
   proc_mapstacks(kpgtbl);
-  
+
   return kpgtbl;
 }
 
 // Initialize the one kernel_pagetable
-void
-kvminit(void)
+void kvminit(void)
 {
   kernel_pagetable = kvmmake();
 }
 
 // Switch h/w page table register to the kernel's page table,
 // and enable paging.
-void
-kvminithart()
+void kvminithart()
 {
   // wait for any previous writes to the page table memory to finish.
   sfence_vma();
@@ -85,15 +83,19 @@ kvminithart()
 pte_t *
 walk(pagetable_t pagetable, uint64 va, int alloc)
 {
-  if(va >= MAXVA)
+  if (va >= MAXVA)
     panic("walk");
 
-  for(int level = 2; level > 0; level--) {
+  for (int level = 2; level > 0; level--)
+  {
     pte_t *pte = &pagetable[PX(level, va)];
-    if(*pte & PTE_V) {
+    if (*pte & PTE_V)
+    {
       pagetable = (pagetable_t)PTE2PA(*pte);
-    } else {
-      if(!alloc || (pagetable = (pde_t*)kalloc()) == 0)
+    }
+    else
+    {
+      if (!alloc || (pagetable = (pde_t *)kalloc()) == 0)
         return 0;
       memset(pagetable, 0, PGSIZE);
       *pte = PA2PTE(pagetable) | PTE_V;
@@ -111,15 +113,15 @@ walkaddr(pagetable_t pagetable, uint64 va)
   pte_t *pte;
   uint64 pa;
 
-  if(va >= MAXVA)
+  if (va >= MAXVA)
     return 0;
 
   pte = walk(pagetable, va, 0);
-  if(pte == 0)
+  if (pte == 0)
     return 0;
-  if((*pte & PTE_V) == 0)
+  if ((*pte & PTE_V) == 0)
     return 0;
-  if((*pte & PTE_U) == 0)
+  if ((*pte & PTE_U) == 0)
     return 0;
   pa = PTE2PA(*pte);
   return pa;
@@ -128,10 +130,9 @@ walkaddr(pagetable_t pagetable, uint64 va)
 // add a mapping to the kernel page table.
 // only used when booting.
 // does not flush TLB or enable paging.
-void
-kvmmap(pagetable_t kpgtbl, uint64 va, uint64 pa, uint64 sz, int perm)
+void kvmmap(pagetable_t kpgtbl, uint64 va, uint64 pa, uint64 sz, int perm)
 {
-  if(mappages(kpgtbl, va, sz, pa, perm) != 0)
+  if (mappages(kpgtbl, va, sz, pa, perm) != 0)
     panic("kvmmap");
 }
 
@@ -139,24 +140,24 @@ kvmmap(pagetable_t kpgtbl, uint64 va, uint64 pa, uint64 sz, int perm)
 // physical addresses starting at pa. va and size might not
 // be page-aligned. Returns 0 on success, -1 if walk() couldn't
 // allocate a needed page-table page.
-int
-mappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)
+int mappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)
 {
   uint64 a, last;
   pte_t *pte;
 
-  if(size == 0)
+  if (size == 0)
     panic("mappages: size");
-  
+
   a = PGROUNDDOWN(va);
   last = PGROUNDDOWN(va + size - 1);
-  for(;;){
-    if((pte = walk(pagetable, a, 1)) == 0)
+  for (;;)
+  {
+    if ((pte = walk(pagetable, a, 1)) == 0)
       return -1;
-    if(*pte & PTE_V)
+    if (*pte & PTE_V)
       panic("mappages: remap");
     *pte = PA2PTE(pa) | perm | PTE_V;
-    if(a == last)
+    if (a == last)
       break;
     a += PGSIZE;
     pa += PGSIZE;
@@ -167,25 +168,26 @@ mappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)
 // Remove npages of mappings starting from va. va must be
 // page-aligned. The mappings must exist.
 // Optionally free the physical memory.
-void
-uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free)
+void uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free)
 {
   uint64 a;
   pte_t *pte;
 
-  if((va % PGSIZE) != 0)
+  if ((va % PGSIZE) != 0)
     panic("uvmunmap: not aligned");
 
-  for(a = va; a < va + npages*PGSIZE; a += PGSIZE){
-    if((pte = walk(pagetable, a, 0)) == 0)
+  for (a = va; a < va + npages * PGSIZE; a += PGSIZE)
+  {
+    if ((pte = walk(pagetable, a, 0)) == 0)
       panic("uvmunmap: walk");
-    if((*pte & PTE_V) == 0)
+    if ((*pte & PTE_V) == 0)
       panic("uvmunmap: not mapped");
-    if(PTE_FLAGS(*pte) == PTE_V)
+    if (PTE_FLAGS(*pte) == PTE_V)
       panic("uvmunmap: not a leaf");
-    if(do_free){
+    if (do_free)
+    {
       uint64 pa = PTE2PA(*pte);
-      kfree((void*)pa);
+      kfree((void *)pa);
     }
     *pte = 0;
   }
@@ -197,8 +199,8 @@ pagetable_t
 uvmcreate()
 {
   pagetable_t pagetable;
-  pagetable = (pagetable_t) kalloc();
-  if(pagetable == 0)
+  pagetable = (pagetable_t)kalloc();
+  if (pagetable == 0)
     return 0;
   memset(pagetable, 0, PGSIZE);
   return pagetable;
@@ -207,16 +209,15 @@ uvmcreate()
 // Load the user initcode into address 0 of pagetable,
 // for the very first process.
 // sz must be less than a page.
-void
-uvmfirst(pagetable_t pagetable, uchar *src, uint sz)
+void uvmfirst(pagetable_t pagetable, uchar *src, uint sz)
 {
   char *mem;
 
-  if(sz >= PGSIZE)
+  if (sz >= PGSIZE)
     panic("uvmfirst: more than a page");
   mem = kalloc();
   memset(mem, 0, PGSIZE);
-  mappages(pagetable, 0, PGSIZE, (uint64)mem, PTE_W|PTE_R|PTE_X|PTE_U);
+  mappages(pagetable, 0, PGSIZE, (uint64)mem, PTE_W | PTE_R | PTE_X | PTE_U);
   memmove(mem, src, sz);
 }
 
@@ -228,18 +229,21 @@ uvmalloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz, int xperm)
   char *mem;
   uint64 a;
 
-  if(newsz < oldsz)
+  if (newsz < oldsz)
     return oldsz;
 
   oldsz = PGROUNDUP(oldsz);
-  for(a = oldsz; a < newsz; a += PGSIZE){
+  for (a = oldsz; a < newsz; a += PGSIZE)
+  {
     mem = kalloc();
-    if(mem == 0){
+    if (mem == 0)
+    {
       uvmdealloc(pagetable, a, oldsz);
       return 0;
     }
     memset(mem, 0, PGSIZE);
-    if(mappages(pagetable, a, PGSIZE, (uint64)mem, PTE_R|PTE_U|xperm) != 0){
+    if (mappages(pagetable, a, PGSIZE, (uint64)mem, PTE_R | PTE_U | xperm) != 0)
+    {
       kfree(mem);
       uvmdealloc(pagetable, a, oldsz);
       return 0;
@@ -255,10 +259,11 @@ uvmalloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz, int xperm)
 uint64
 uvmdealloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz)
 {
-  if(newsz >= oldsz)
+  if (newsz >= oldsz)
     return oldsz;
 
-  if(PGROUNDUP(newsz) < PGROUNDUP(oldsz)){
+  if (PGROUNDUP(newsz) < PGROUNDUP(oldsz))
+  {
     int npages = (PGROUNDUP(oldsz) - PGROUNDUP(newsz)) / PGSIZE;
     uvmunmap(pagetable, PGROUNDUP(newsz), npages, 1);
   }
@@ -268,31 +273,42 @@ uvmdealloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz)
 
 // Recursively free page-table pages.
 // All leaf mappings must already have been removed.
-void
-freewalk(pagetable_t pagetable)
+void freewalk(pagetable_t pagetable)
 {
   // there are 2^9 = 512 PTEs in a page table.
-  for(int i = 0; i < 512; i++){
+  for (int i = 0; i < 512; i++)
+  {
     pte_t pte = pagetable[i];
-    if((pte & PTE_V) && (pte & (PTE_R|PTE_W|PTE_X)) == 0){
+    if ((pte & PTE_V) && (pte & (PTE_R | PTE_W | PTE_X)) == 0)
+    {
       // this PTE points to a lower-level page table.
       uint64 child = PTE2PA(pte);
       freewalk((pagetable_t)child);
       pagetable[i] = 0;
-    } else if(pte & PTE_V){
+    }
+    else if (pte & PTE_V)
+    {
       panic("freewalk: leaf");
     }
   }
-  kfree((void*)pagetable);
+  kfree((void *)pagetable);
 }
 
 // Free user memory pages,
 // then free page-table pages.
-void
-uvmfree(pagetable_t pagetable, uint64 sz)
+void uvmfree(pagetable_t pagetable, uint64 sz)
+{
+  if (sz > 0)
+    uvmunmap(pagetable, 0, PGROUNDUP(sz) / PGSIZE, 1);
+  freewalk(pagetable);
+}
+
+// Free user memory pages for thread
+// But don't free page-table pages physically
+void uvmfreethread(pagetable_t pagetable, uint64 sz)
 {
-  if(sz > 0)
-    uvmunmap(pagetable, 0, PGROUNDUP(sz)/PGSIZE, 1);
+  if (sz > 0)
+    uvmunmap(pagetable, 0, PGROUNDUP(sz) / PGSIZE, 0);
   freewalk(pagetable);
 }
 
@@ -302,45 +318,111 @@ uvmfree(pagetable_t pagetable, uint64 sz)
 // physical memory.
 // returns 0 on success, -1 on failure.
 // frees any allocated pages on failure.
-int
-uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
+int uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
 {
   pte_t *pte;
   uint64 pa, i;
   uint flags;
   char *mem;
 
-  for(i = 0; i < sz; i += PGSIZE){
-    if((pte = walk(old, i, 0)) == 0)
+  for (i = 0; i < sz; i += PGSIZE)
+  {
+    if ((pte = walk(old, i, 0)) == 0)
       panic("uvmcopy: pte should exist");
-    if((*pte & PTE_V) == 0)
+    if ((*pte & PTE_V) == 0)
       panic("uvmcopy: page not present");
     pa = PTE2PA(*pte);
     flags = PTE_FLAGS(*pte);
-    if((mem = kalloc()) == 0)
+    if ((mem = kalloc()) == 0)
       goto err;
-    memmove(mem, (char*)pa, PGSIZE);
-    if(mappages(new, i, PGSIZE, (uint64)mem, flags) != 0){
+    memmove(mem, (char *)pa, PGSIZE);
+    if (mappages(new, i, PGSIZE, (uint64)mem, flags) != 0)
+    {
       kfree(mem);
       goto err;
     }
   }
   return 0;
 
- err:
+err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
+// uvmmirror for thread creation. Doesn't use kalloc. Doesn't allocate new pages.
+int uvmmirror(pagetable_t old, pagetable_t new, uint64 sz)
+{
+  pte_t *pte;
+  // pte_t *newpte;
+  uint64 pa;
+  uint64 i;
+  uint flags;
+
+  for (i = 0; i < sz; i += PGSIZE)
+  {
+    if ((pte = walk(old, i, 0)) == 0)
+      panic("uvmmirror: pte should exist");
+    if ((*pte & PTE_V) == 0)
+      panic("uvmmirror: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+
+    if (mappages(new, i, PGSIZE, (uint64)pa, flags) != 0)
+    {
+      goto err;
+    }
+    // if((pte = walk(old, i, 0)) == 0)
+    //   panic("uvmmirror: pte should exist");
+    // if((newpte = walk(new, i, 1)) == 0)
+    //   panic("uvmmirror: newpte should exist");
+    // *newpte = *pte;
+  }
+  return 0;
+
+err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
+// uvmmirror for growproc. Doesn't use kalloc. Doesn't allocate new pages.
+// call mappages on PGROUNDUP(old size) to sz, instead of 0 to sz.
+
+int uvmmirrorgrow(pagetable_t old, pagetable_t new, uint64 oldsz, uint64 sz)
+{
+  pte_t *pte;
+  uint64 pa;
+  uint64 i;
+  uint flags;
+
+  for (i = PGROUNDUP(oldsz); i < sz; i += PGSIZE)
+  {
+    if ((pte = walk(old, i, 0)) == 0)
+      panic("uvmmirror: pte should exist");
+    if ((*pte & PTE_V) == 0)
+      panic("uvmmirror: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+
+    if (mappages(new, i, PGSIZE, (uint64)pa, flags) != 0)
+    {
+      goto err;
+    }
+  }
+  return 0;
+
+err:
   uvmunmap(new, 0, i / PGSIZE, 1);
   return -1;
 }
 
 // mark a PTE invalid for user access.
 // used by exec for the user stack guard page.
-void
-uvmclear(pagetable_t pagetable, uint64 va)
+void uvmclear(pagetable_t pagetable, uint64 va)
 {
   pte_t *pte;
-  
+
   pte = walk(pagetable, va, 0);
-  if(pte == 0)
+  if (pte == 0)
     panic("uvmclear");
   *pte &= ~PTE_U;
 }
@@ -348,18 +430,18 @@ uvmclear(pagetable_t pagetable, uint64 va)
 // Copy from kernel to user.
 // Copy len bytes from src to virtual address dstva in a given page table.
 // Return 0 on success, -1 on error.
-int
-copyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len)
+int copyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len)
 {
   uint64 n, va0, pa0;
 
-  while(len > 0){
+  while (len > 0)
+  {
     va0 = PGROUNDDOWN(dstva);
     pa0 = walkaddr(pagetable, va0);
-    if(pa0 == 0)
+    if (pa0 == 0)
       return -1;
     n = PGSIZE - (dstva - va0);
-    if(n > len)
+    if (n > len)
       n = len;
     memmove((void *)(pa0 + (dstva - va0)), src, n);
 
@@ -370,21 +452,35 @@ copyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len)
   return 0;
 }
 
+int copyoutlock(pagetable_t pagetable, uint64 dstva)
+{
+  uint64 va0, pa0;
+
+  va0 = PGROUNDDOWN(dstva);
+  pa0 = walkaddr(pagetable, va0);
+  if (pa0 == 0)
+    return -1;
+  __sync_synchronize();
+  __sync_lock_release((uint8 *)(pa0 + (dstva - va0)));
+
+  return 0;
+}
+
 // Copy from user to kernel.
 // Copy len bytes to dst from virtual address srcva in a given page table.
 // Return 0 on success, -1 on error.
-int
-copyin(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len)
+int copyin(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len)
 {
   uint64 n, va0, pa0;
 
-  while(len > 0){
+  while (len > 0)
+  {
     va0 = PGROUNDDOWN(srcva);
     pa0 = walkaddr(pagetable, va0);
-    if(pa0 == 0)
+    if (pa0 == 0)
       return -1;
     n = PGSIZE - (srcva - va0);
-    if(n > len)
+    if (n > len)
       n = len;
     memmove(dst, (void *)(pa0 + (srcva - va0)), n);
 
@@ -399,28 +495,32 @@ copyin(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len)
 // Copy bytes to dst from virtual address srcva in a given page table,
 // until a '\0', or max.
 // Return 0 on success, -1 on error.
-int
-copyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max)
+int copyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max)
 {
   uint64 n, va0, pa0;
   int got_null = 0;
 
-  while(got_null == 0 && max > 0){
+  while (got_null == 0 && max > 0)
+  {
     va0 = PGROUNDDOWN(srcva);
     pa0 = walkaddr(pagetable, va0);
-    if(pa0 == 0)
+    if (pa0 == 0)
       return -1;
     n = PGSIZE - (srcva - va0);
-    if(n > max)
+    if (n > max)
       n = max;
 
-    char *p = (char *) (pa0 + (srcva - va0));
-    while(n > 0){
-      if(*p == '\0'){
+    char *p = (char *)(pa0 + (srcva - va0));
+    while (n > 0)
+    {
+      if (*p == '\0')
+      {
         *dst = '\0';
         got_null = 1;
         break;
-      } else {
+      }
+      else
+      {
         *dst = *p;
       }
       --n;
@@ -431,9 +531,12 @@ copyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max)
 
     srcva = va0 + PGSIZE;
   }
-  if(got_null){
+  if (got_null)
+  {
     return 0;
-  } else {
+  }
+  else
+  {
     return -1;
   }
 }
diff --git a/user/producer_consumer.c b/user/producer_consumer.c
new file mode 100644
index 0000000..8e75aa9
--- /dev/null
+++ b/user/producer_consumer.c
@@ -0,0 +1,133 @@
+#include "user/thread_spinlock.h"
+#include "user/thread_mutex.h"
+
+
+struct queue2
+{
+	int arr[16];
+	int front;
+	int rear;
+	int size;
+};
+
+struct queue2 q;
+
+void queue2()
+{
+	q.front = 0;
+	q.rear = 0;
+	q.size = 0;
+}
+void push2(int x)
+{
+	q.arr[q.rear] = x;
+	q.rear = (q.rear + 1) % 16;
+	q.size++;
+}
+int getFront2()
+{
+	if (q.size == 0)
+		return -1;
+	return q.arr[q.front];
+}
+void pop2()
+{
+	q.front = (q.front + 1) % 16;
+	q.size--;
+}
+
+
+struct sem_t empty;
+struct sem_t full;
+struct thread_mutex lock;
+
+void init_semaphore()
+{
+	thread_mutex_init(&lock, "lock");
+	sem_init(&empty, 5);
+	sem_init(&full, 0);
+}
+
+void ProducerFunc(void *arg)
+{
+	thread_mutex_lock(&lock);
+	printf("%s\n", (char *)arg);
+	thread_mutex_unlock(&lock);
+	
+	int i;
+	for (i = 1; i <= 10; i++)
+	{
+		// wait for semphore empty
+		sem_wait(&empty);
+
+		// wait for mutex lock
+		thread_mutex_lock(&lock);
+
+		sleep(1);
+		push2(i);
+		printf("producer produced item %d\n", i);
+
+		// unlock mutex lock
+		thread_mutex_unlock(&lock);
+		// post semaphore full
+		sem_signal(&full);
+	}
+    thread_exit();
+	return;
+}
+
+void ConsumerFunc(void *arg)
+{
+	thread_mutex_lock(&lock);
+	printf("%s\n", (char *)arg);
+	thread_mutex_unlock(&lock);
+
+	int i;
+	for (i = 1; i <= 10; i++)
+	{
+		// wait for semphore full
+		sem_wait(&full);
+		// wait for mutex lock
+		// lock mutex lock
+		thread_mutex_lock(&lock);
+
+		sleep(1);
+		int item = getFront2();
+		pop2();
+		printf("consumer consumed item %d\n", item);
+
+		// unlock mutex lock
+		thread_mutex_unlock(&lock);
+		// post semaphore empty
+		sem_signal(&empty);
+	}
+    thread_exit();
+	return;
+}
+
+int main(void)
+{
+
+	init_semaphore();
+
+	char *message1 = "i am producer";
+	char *message2 = "i am consumer";
+
+	void *s1, *s2;
+	int thread1, thread2, r1, r2;
+
+	s1 = malloc(4096);
+	s2 = malloc(4096);
+
+	thread1 = thread_create(ProducerFunc, (void *)message1, s1);
+	thread2 = thread_create(ConsumerFunc, (void *)message2, s2);
+
+	r1 = thread_join(thread1);
+	r2 = thread_join(thread2);
+
+	// print value of r1 and r2
+	printf("r1 = %d\n", r1);
+	printf("r2 = %d\n", r2);
+
+	exit(0);
+}
diff --git a/user/thread_mutex.h b/user/thread_mutex.h
new file mode 100644
index 0000000..da7eb1b
--- /dev/null
+++ b/user/thread_mutex.h
@@ -0,0 +1,205 @@
+#ifndef _THREAD_MUTEX_H_
+#define _THREAD_MUTEX_H_
+
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+
+#define LOCKED 1
+#define UNLOCKED 0
+
+// Mutual exclusion lock.
+struct thread_mutex {
+
+  uint8 locked;       // Is the lock held?
+
+  // For debugging:
+  char *name;        // Name of lock.
+};
+
+struct queue{
+	int arr[16];
+	int front;
+	int rear;
+	int size;
+};
+
+
+// We'll use this queue to store the pid of the waiting threads
+struct condition{
+    struct queue q;
+    struct thread_mutex mx;
+    struct thread_mutex list_lock;
+};
+
+struct sem_t {
+    int count;
+    struct thread_mutex mx;
+    struct condition cv;    // condition variable
+};
+
+	void queue_init(struct queue *q)
+  {
+    q->front = 0;
+    q->rear = 0;
+    q->size = 0;
+  }
+
+	void push(struct queue *q, int x)
+  {
+    q->arr[q->rear] = x;
+    q->rear = (q->rear+1)%16;
+    q->size++;
+  }
+
+	int getFront(struct queue *q)
+  {
+    return q->arr[q->front];
+  }
+	void pop(struct queue *q)
+  {
+    q->front = (q->front+1)%16;
+    q->size--;
+  }
+
+
+void
+thread_mutex_init(struct thread_mutex *m, char *name)
+{
+  m->name = name;
+  m->locked = UNLOCKED;
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+void
+thread_mutex_lock(struct thread_mutex *m)
+{
+
+  // On RISC-V, sync_lock_test_and_set turns into an atomic swap:
+  //   a5 = 1
+  //   s1 = &lk->locked
+  //   amoswap.w.aq a5, a5, (s1)
+  while(__sync_lock_test_and_set(&m->locked, 1) != 0)
+  {
+    sleep(1);
+  }
+
+  // Tell the C compiler and the processor to not move loads or stores
+  // past this point, to ensure that the critical section's memory
+  // references happen strictly after the lock is acquired.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+}
+
+// Release the lock.
+void
+thread_mutex_unlock(struct thread_mutex *m)
+{
+
+  // Tell the C compiler and the CPU to not move loads or stores
+  // past this point, to ensure that all the stores in the critical
+  // section are visible to other CPUs before the lock is released,
+  // and that loads in the critical section occur strictly before
+  // the lock is released.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to lk->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &lk->locked
+  //   amoswap.w zero, zero, (s1)
+  __sync_lock_release(&m->locked);
+
+}
+
+
+// initialize the condition variables
+void thread_cond_init(struct condition *cond){
+    // initialize the mutex
+    thread_mutex_init(&cond->mx, "cond");
+    thread_mutex_init(&cond->list_lock, "list_lock");
+
+    // initialize the queue
+    queue_init(&cond->q);
+}
+
+// wait on the condition variable
+void thread_cond_wait(struct condition *cond, struct thread_mutex *mx){
+    // acquire the lock on the condition variable
+    thread_mutex_lock(&cond->list_lock);
+
+    // push the pid of the current thread in the queue
+    push(&cond->q, getpid());
+
+    // release the lock on the condition variable
+    thread_mutex_unlock(&cond->list_lock);
+
+    // thread_mutex_lock(mx);
+
+    thread_sleep(&mx->locked);
+
+    // acquire the lock on the condition variable
+    thread_mutex_lock(mx);
+
+    return;
+}
+
+void thread_cond_signal(struct condition *cond){
+    // acquire the lock on the condition variable
+    thread_mutex_lock(&cond->list_lock);
+
+    // if the queue is empty, return
+    if(cond->q.size==0){
+        thread_mutex_unlock(&cond->list_lock);
+        return;
+    }
+
+    // get the pid of the thread to be woken up
+    int pid = getFront(&cond->q);
+
+    // pop the pid from the queue
+    pop(&cond->q);
+
+    // release the lock on the condition variable
+    thread_mutex_unlock(&cond->list_lock);
+
+    // wake up the thread
+    thread_wakeup(pid);
+
+    return;
+}
+
+// initialize the semaphore
+int sem_init(struct sem_t *s, int value){
+    s->count = value;
+    thread_mutex_init(&s->mx, "sem");
+    thread_cond_init(&s->cv);
+    return 0;
+}
+
+// wait on the semaphore
+int sem_wait(struct sem_t *s){
+    thread_mutex_lock(&s->mx);
+    while(s->count==0){
+        thread_cond_wait(&s->cv, &s->mx);
+    }
+    s->count--;
+    thread_mutex_unlock(&s->mx);
+    return 0;
+}
+
+// signal the semaphore
+int sem_signal(struct sem_t *s){
+    thread_mutex_lock(&s->mx);
+    s->count++;
+    thread_cond_signal(&s->cv);
+    thread_mutex_unlock(&s->mx);
+    return 0;
+}
+
+
+#endif // _THREAD_MUTEX_H_
\ No newline at end of file
diff --git a/user/thread_spinlock.h b/user/thread_spinlock.h
new file mode 100644
index 0000000..339dbdd
--- /dev/null
+++ b/user/thread_spinlock.h
@@ -0,0 +1,63 @@
+// Mutual exclusion lock.
+#include "kernel/types.h"
+
+struct thread_spinlock {
+    
+  uint8 locked;      // Is the lock held?
+
+  // For debugging:
+  char *name;        // Name of lock.
+
+};
+
+void
+thread_spin_init(struct thread_spinlock *lk, char *name)
+{
+  lk->name = name;
+  lk->locked = 0;
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+void
+thread_spin_lock(struct thread_spinlock *lk)
+{
+
+  // On RISC-V, sync_lock_test_and_set turns into an atomic swap:
+  //   a5 = 1
+  //   s1 = &lk->locked
+  //   amoswap.w.aq a5, a5, (s1)
+  while(__sync_lock_test_and_set(&lk->locked, 1) != 0)
+    ;
+
+  // Tell the C compiler and the processor to not move loads or stores
+  // past this point, to ensure that the critical section's memory
+  // references happen strictly after the lock is acquired.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+}
+
+// Release the lock.
+void
+thread_spin_unlock(struct thread_spinlock *lk)
+{
+
+  // Tell the C compiler and the CPU to not move loads or stores
+  // past this point, to ensure that all the stores in the critical
+  // section are visible to other CPUs before the lock is released,
+  // and that loads in the critical section occur strictly before
+  // the lock is released.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to lk->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &lk->locked
+  //   amoswap.w zero, zero, (s1)
+  __sync_lock_release(&lk->locked);
+
+}
diff --git a/user/threads.c b/user/threads.c
new file mode 100644
index 0000000..b9f9c32
--- /dev/null
+++ b/user/threads.c
@@ -0,0 +1,94 @@
+#ifndef _THREADS_C_
+#define _THREADS_C_
+
+// #include "kernel/types.h"
+// #include "kernel/stat.h"
+// #include "user/user.h"
+#include "user/thread_spinlock.h"
+#include "user/thread_mutex.h"
+
+struct thread_mutex mlock;
+// struct sem_t mlock;
+struct thread_spinlock lock;
+
+struct balance
+{
+    char name[32];
+    int amount;
+};
+
+volatile int total_balance = 0;
+
+volatile unsigned int delay(unsigned int d)
+{
+    unsigned int i;
+    for (i = 0; i < d; i++)
+    {
+        __asm volatile("nop" ::
+                           :);
+    }
+
+    return i;
+}
+
+void do_work(void *arg)
+{
+    int i;
+    int old;
+
+    thread_spin_lock(&lock);
+    struct balance *b = (struct balance *)arg;
+    printf("Starting do_work: s:%s\n", b->name);
+    thread_spin_unlock(&lock);
+
+    for (i = 0; i < b->amount; i++)
+    {
+        // lock and mlock will be implemented by you.
+        thread_spin_lock(&lock);
+        thread_mutex_lock(&mlock);
+        // sem_wait(&mlock);
+        old = total_balance;
+        delay(100000);
+        if (old != total_balance)
+            printf("we will miss an update. old: %d total_balance: %d\n", old, total_balance);
+        total_balance = old + 1;
+        thread_spin_unlock(&lock);
+        thread_mutex_unlock(&mlock);
+        // sem_signal(&mlock);
+    }
+
+    printf("Done s:%x\n", b->name);
+
+    thread_exit();
+    return;
+}
+
+int main(int argc, char *argv[])
+{
+
+    struct balance b1 = {"b1", 3200};
+    struct balance b2 = {"b2", 2800};
+
+    void *s1, *s2;
+    int thread1, thread2, r1, r2;
+
+    thread_spin_init(&lock, "balance_lock");
+    thread_mutex_init(&mlock, "balance_lock");
+    // sem_init(&mlock, 1);
+
+    s1 = malloc(4096); // 4096 is the PGSIZE defined in kernel/riscv.h
+    s2 = malloc(4096);
+
+    thread1 = thread_create(do_work, (void *)&b1, s1);
+    thread2 = thread_create(do_work, (void *)&b2, s2);
+
+    r1 = thread_join(thread1);
+    r2 = thread_join(thread2);
+
+    printf("Threads finished: (%d):%d, (%d):%d, shared balance:%d\n",
+           thread1, r1, thread2, r2, total_balance);
+
+    exit(0);
+}
+
+#endif
\ No newline at end of file
diff --git a/user/user.h b/user/user.h
index 4d398d5..b59ab47 100644
--- a/user/user.h
+++ b/user/user.h
@@ -22,6 +22,11 @@ int getpid(void);
 char* sbrk(int);
 int sleep(int);
 int uptime(void);
+int thread_create(void (*)(void*), void*, void*);
+int thread_join(int);
+void thread_exit(void);
+void thread_sleep(uint8*);
+void thread_wakeup(int);
 
 // ulib.c
 int stat(const char*, struct stat*);
diff --git a/user/usys.pl b/user/usys.pl
index 01e426e..1a06917 100755
--- a/user/usys.pl
+++ b/user/usys.pl
@@ -36,3 +36,8 @@ entry("getpid");
 entry("sbrk");
 entry("sleep");
 entry("uptime");
+entry("thread_create");
+entry("thread_exit");
+entry("thread_join");
+entry("thread_sleep");
+entry("thread_wakeup");
\ No newline at end of file
